 Contactless ATM System

A **Contactless ATM System** leveraging cutting-edge technologies such as hand gesture recognition and face recognition to provide a secure, efficient, and hygienic banking experience. This project demonstrates the integration of modern machine learning and computer vision techniques into traditional ATM functionalities to enhance user convenience and security.

---

## 📝 Project Overview

The **Contactless ATM System** aims to:
- Minimize physical contact with ATMs, reducing the risk of germ transmission.
- Enhance security using **face recognition** for user authentication.
- Introduce **hand gesture recognition** for intuitive user interactions.
- Provide a seamless and user-friendly banking experience.

---

## 💡 Key Features
1. **Gesture-Based Navigation**: Users can perform basic ATM operations (withdrawal, balance inquiry, etc.) using predefined hand gestures.
2. **Face Recognition for Authentication**: The system ensures secure access by verifying the user's identity using facial recognition.
3. **Hygienic Transactions**: Eliminates the need for physical contact with the ATM.
4. **Real-Time Processing**: Fast and accurate detection and processing of gestures and facial data.

---

## 📁 Project Structure

- **/src**: Contains the core source code for gesture recognition, face recognition, and ATM system integration.
- **/models**: Pre-trained models used for gesture and face recognition.
- **/data**: Dataset used for training and testing the models.
- **/docs**: Documentation and additional resources.
- **/scripts**: Utility scripts for data preprocessing, training, and testing.

---

## 🔧 Installation and Setup

### Prerequisites
- Python 3.7 or above
- OpenCV
- TensorFlow/Keras
- Other dependencies listed in `requirements.txt`

### Steps
1. Clone this repository:
   ```bash
   git clone https://github.com/Virag-JN/Contactless-ATM-System.git
   ```
2. Navigate to the project directory:
   ```bash
   cd Contactless-ATM-System
   ```
3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Run the application:
   ```bash
   python main.py
   ```

---

## 📊 Dataset

- **Gesture Dataset**: Predefined hand gestures for system navigation.
- **Face Dataset**: Images for face recognition training and validation.

*Note: You can add your custom dataset by following the instructions in the `/docs` folder.*

---

## 🚀 Future Enhancements

- Integration with NFC for cardless transactions.
- Adding voice-based authentication for enhanced accessibility.
- Supporting additional gestures for more comprehensive navigation.

---

## 🤝 Contributing

Contributions are welcome! Please follow these steps:
1. Fork the repository.
2. Create a feature branch: `git checkout -b feature-name`.
3. Commit your changes: `git commit -m "Added feature-name"`.
4. Push to the branch: `git push origin feature-name`.
5. Submit a pull request.

---

## 🛡️ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## 🙌 Acknowledgments

Special thanks to:
- Open-source contributors for datasets and pre-trained models.
- The Python and open-source developer community for robust libraries and frameworks.

For more information, feel free to contact me or raise an issue in this repository.

---

